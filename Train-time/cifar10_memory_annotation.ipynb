{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 Matthieu Courbariaux\n",
    "\n",
    "# This file is part of BinaryNet.\n",
    "\n",
    "# BinaryNet is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "\n",
    "# BinaryNet is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with BinaryNet.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1234) # for reproducibility?\n",
    "\n",
    "# specifying the gpu to use\n",
    "# import theano.sandbox.cuda\n",
    "# theano.sandbox.cuda.use('gpu1') \n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "import cPickle as pickle\n",
    "import gzip\n",
    "\n",
    "import binary_net\n",
    "\n",
    "from pylearn2.datasets.zca_dataset import ZCA_Dataset   \n",
    "from pylearn2.datasets.cifar10 import CIFAR10 \n",
    "from pylearn2.utils import serial\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size = 50\n",
      "alpha = 0.1\n",
      "epsilon = 0.0001\n",
      "activation = binary_net.binary_tanh_unit\n",
      "binary = True\n",
      "stochastic = False\n",
      "H = 1.0\n",
      "W_LR_scale = Glorot\n",
      "num_epochs = 500\n",
      "LR_start = 0.001\n",
      "LR_fin = 3e-07\n",
      "LR_decay = 0.983907435305\n",
      "train_set_size = 45000\n",
      "shuffle_parts = 1\n"
     ]
    }
   ],
   "source": [
    "# BN parameters\n",
    "batch_size = 50\n",
    "print(\"batch_size = \"+str(batch_size))\n",
    "# alpha is the exponential moving average factor\n",
    "alpha = .1\n",
    "print(\"alpha = \"+str(alpha))\n",
    "epsilon = 1e-4\n",
    "print(\"epsilon = \"+str(epsilon))\n",
    "\n",
    "# BinaryOut\n",
    "activation = binary_net.binary_tanh_unit\n",
    "print(\"activation = binary_net.binary_tanh_unit\")\n",
    "# activation = binary_net.binary_sigmoid_unit\n",
    "# print(\"activation = binary_net.binary_sigmoid_unit\")\n",
    "\n",
    "# BinaryConnect    \n",
    "binary = True\n",
    "print(\"binary = \"+str(binary))\n",
    "stochastic = False\n",
    "print(\"stochastic = \"+str(stochastic))\n",
    "# (-H,+H) are the two binary values\n",
    "# H = \"Glorot\"\n",
    "H = 1.\n",
    "print(\"H = \"+str(H))\n",
    "# W_LR_scale = 1.    \n",
    "W_LR_scale = \"Glorot\" # \"Glorot\" means we are using the coefficients from Glorot's paper\n",
    "print(\"W_LR_scale = \"+str(W_LR_scale))\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 500\n",
    "print(\"num_epochs = \"+str(num_epochs))\n",
    "\n",
    "# Decaying LR \n",
    "LR_start = 0.001\n",
    "print(\"LR_start = \"+str(LR_start))\n",
    "LR_fin = 0.0000003\n",
    "print(\"LR_fin = \"+str(LR_fin))\n",
    "LR_decay = (LR_fin/LR_start)**(1./num_epochs)\n",
    "print(\"LR_decay = \"+str(LR_decay))\n",
    "# BTW, LR decay might good for the BN moving average...\n",
    "\n",
    "train_set_size = 45000\n",
    "print(\"train_set_size = \"+str(train_set_size))\n",
    "shuffle_parts = 1\n",
    "print(\"shuffle_parts = \"+str(shuffle_parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inject_batch_size(shape, batch_size):\n",
    "    shape = list(shape)\n",
    "    shape[0] = batch_size\n",
    "    return tuple(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data Memory (float)] (50, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Prepare Theano variables for inputs and targets\n",
    "input = T.tensor4('inputs')\n",
    "target = T.matrix('targets')\n",
    "LR = T.scalar('LR', dtype=theano.config.floatX)\n",
    "\n",
    "cnn = lasagne.layers.InputLayer(\n",
    "        shape=(None, 3, 32, 32),\n",
    "        input_var=input)\n",
    "print(\"[Data Memory (float)]\", inject_batch_size(cnn.output_shape, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter Memory (binary)] (128, 3, 3)\n",
      "[Data Memory (binary)] (50, 128, 32, 32)\n",
      "[Parameter Memory (binary)] (128, 3, 3)\n",
      "[Data Memory (binary)] (50, 128, 32, 32)\n",
      "[Data Memory (binary)] (50, 128, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "# 128C3-128C3-P2             \n",
    "cnn = binary_net.Conv2DLayer(\n",
    "        cnn, \n",
    "        binary=binary,\n",
    "        stochastic=stochastic,\n",
    "        H=H,\n",
    "        W_LR_scale=W_LR_scale,\n",
    "        num_filters=128, \n",
    "        filter_size=(3, 3),\n",
    "        pad=1,\n",
    "        nonlinearity=lasagne.nonlinearities.identity)\n",
    "print(\"[Parameter Memory (binary)]\", \"(128, 3, 3)\")\n",
    "print(\"[Data Memory (binary)]\", inject_batch_size(cnn.output_shape, batch_size))\n",
    "\n",
    "cnn = lasagne.layers.BatchNormLayer(\n",
    "        cnn,\n",
    "        epsilon=epsilon, \n",
    "        alpha=alpha)\n",
    "\n",
    "cnn = lasagne.layers.NonlinearityLayer(\n",
    "        cnn,\n",
    "        nonlinearity=activation) \n",
    "\n",
    "cnn = binary_net.Conv2DLayer(\n",
    "        cnn, \n",
    "        binary=binary,\n",
    "        stochastic=stochastic,\n",
    "        H=H,\n",
    "        W_LR_scale=W_LR_scale,\n",
    "        num_filters=128, \n",
    "        filter_size=(3, 3),\n",
    "        pad=1,\n",
    "        nonlinearity=lasagne.nonlinearities.identity)\n",
    "print(\"[Parameter Memory (binary)]\", \"(128, 3, 3)\")\n",
    "print(\"[Data Memory (binary)]\", inject_batch_size(cnn.output_shape, batch_size))\n",
    "\n",
    "cnn = lasagne.layers.MaxPool2DLayer(cnn, pool_size=(2, 2))\n",
    "print(\"[Data Memory (binary)]\", inject_batch_size(cnn.output_shape, batch_size))\n",
    "\n",
    "cnn = lasagne.layers.BatchNormLayer(\n",
    "        cnn,\n",
    "        epsilon=epsilon, \n",
    "        alpha=alpha)\n",
    "\n",
    "cnn = lasagne.layers.NonlinearityLayer(\n",
    "        cnn,\n",
    "        nonlinearity=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter Memory (binary)] (256, 3, 3)\n",
      "[Data Memory (binary)] (50, 256, 16, 16)\n",
      "[Parameter Memory (binary)] (256, 3, 3)\n",
      "[Data Memory (binary)] (50, 256, 16, 16)\n",
      "[Data Memory (binary)] (50, 256, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "# 256C3-256C3-P2             \n",
    "cnn = binary_net.Conv2DLayer(\n",
    "        cnn, \n",
    "        binary=binary,\n",
    "        stochastic=stochastic,\n",
    "        H=H,\n",
    "        W_LR_scale=W_LR_scale,\n",
    "        num_filters=256, \n",
    "        filter_size=(3, 3),\n",
    "        pad=1,\n",
    "        nonlinearity=lasagne.nonlinearities.identity)\n",
    "print(\"[Parameter Memory (binary)]\", \"(256, 3, 3)\")\n",
    "print(\"[Data Memory (binary)]\", inject_batch_size(cnn.output_shape, batch_size))\n",
    "\n",
    "cnn = lasagne.layers.BatchNormLayer(\n",
    "        cnn,\n",
    "        epsilon=epsilon, \n",
    "        alpha=alpha)\n",
    "\n",
    "cnn = lasagne.layers.NonlinearityLayer(\n",
    "        cnn,\n",
    "        nonlinearity=activation) \n",
    "\n",
    "cnn = binary_net.Conv2DLayer(\n",
    "        cnn, \n",
    "        binary=binary,\n",
    "        stochastic=stochastic,\n",
    "        H=H,\n",
    "        W_LR_scale=W_LR_scale,\n",
    "        num_filters=256, \n",
    "        filter_size=(3, 3),\n",
    "        pad=1,\n",
    "        nonlinearity=lasagne.nonlinearities.identity)\n",
    "print(\"[Parameter Memory (binary)]\", \"(256, 3, 3)\")\n",
    "print(\"[Data Memory (binary)]\", inject_batch_size(cnn.output_shape, batch_size))\n",
    "\n",
    "cnn = lasagne.layers.MaxPool2DLayer(cnn, pool_size=(2, 2))\n",
    "print(\"[Data Memory (binary)]\", inject_batch_size(cnn.output_shape, batch_size))\n",
    "\n",
    "cnn = lasagne.layers.BatchNormLayer(\n",
    "        cnn,\n",
    "        epsilon=epsilon, \n",
    "        alpha=alpha)\n",
    "\n",
    "cnn = lasagne.layers.NonlinearityLayer(\n",
    "        cnn,\n",
    "        nonlinearity=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter Memory (binary)] (512, 3, 3)\n",
      "[Data Memory (binary)] (50, 512, 8, 8)\n",
      "[Parameter Memory (binary)] (512, 3, 3)\n",
      "[Data Memory (binary)] (None, 512, 8, 8)\n",
      "[Data Memory (binary)] (50, 512, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "# 512C3-512C3-P2              \n",
    "cnn = binary_net.Conv2DLayer(\n",
    "        cnn, \n",
    "        binary=binary,\n",
    "        stochastic=stochastic,\n",
    "        H=H,\n",
    "        W_LR_scale=W_LR_scale,\n",
    "        num_filters=512, \n",
    "        filter_size=(3, 3),\n",
    "        pad=1,\n",
    "        nonlinearity=lasagne.nonlinearities.identity)\n",
    "print(\"[Parameter Memory (binary)]\", \"(512, 3, 3)\")\n",
    "print(\"[Data Memory (binary)]\", inject_batch_size(cnn.output_shape, batch_size))\n",
    "\n",
    "cnn = lasagne.layers.BatchNormLayer(\n",
    "        cnn,\n",
    "        epsilon=epsilon, \n",
    "        alpha=alpha)\n",
    "\n",
    "cnn = lasagne.layers.NonlinearityLayer(\n",
    "        cnn,\n",
    "        nonlinearity=activation)\n",
    "\n",
    "cnn = binary_net.Conv2DLayer(\n",
    "        cnn, \n",
    "        binary=binary,\n",
    "        stochastic=stochastic,\n",
    "        H=H,\n",
    "        W_LR_scale=W_LR_scale,\n",
    "        num_filters=512, \n",
    "        filter_size=(3, 3),\n",
    "        pad=1,\n",
    "        nonlinearity=lasagne.nonlinearities.identity)\n",
    "print(\"[Parameter Memory (binary)]\", \"(512, 3, 3)\")\n",
    "print(\"[Data Memory (binary)]\", cnn.output_shape)\n",
    "\n",
    "cnn = lasagne.layers.MaxPool2DLayer(cnn, pool_size=(2, 2))\n",
    "print(\"[Data Memory (binary)]\", inject_batch_size(cnn.output_shape, batch_size))\n",
    "\n",
    "cnn = lasagne.layers.BatchNormLayer(\n",
    "        cnn,\n",
    "        epsilon=epsilon, \n",
    "        alpha=alpha)\n",
    "\n",
    "cnn = lasagne.layers.NonlinearityLayer(\n",
    "        cnn,\n",
    "        nonlinearity=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter Memory (binary)] (16, 1024)\n",
      "[Data Memory (binary)] (50, 1024)\n",
      "[Parameter Memory (binary)] (1024, 1024)\n",
      "[Data Memory (binary)] (50, 1024)\n",
      "[Parameter Memory (binary)] (1024, 10)\n",
      "[Data Memory (binary)] (50, 10)\n"
     ]
    }
   ],
   "source": [
    "# 1024FP-1024FP-10FP            \n",
    "cnn = binary_net.DenseLayer(\n",
    "            cnn, \n",
    "            binary=binary,\n",
    "            stochastic=stochastic,\n",
    "            H=H,\n",
    "            W_LR_scale=W_LR_scale,\n",
    "            nonlinearity=lasagne.nonlinearities.identity,\n",
    "            num_units=1024)\n",
    "print(\"[Parameter Memory (binary)]\", \"(16, 1024)\")\n",
    "print(\"[Data Memory (binary)]\", inject_batch_size(cnn.output_shape, batch_size))\n",
    "\n",
    "cnn = lasagne.layers.BatchNormLayer(\n",
    "        cnn,\n",
    "        epsilon=epsilon, \n",
    "        alpha=alpha)\n",
    "\n",
    "cnn = lasagne.layers.NonlinearityLayer(\n",
    "        cnn,\n",
    "        nonlinearity=activation) \n",
    "\n",
    "cnn = binary_net.DenseLayer(\n",
    "            cnn, \n",
    "            binary=binary,\n",
    "            stochastic=stochastic,\n",
    "            H=H,\n",
    "            W_LR_scale=W_LR_scale,\n",
    "            nonlinearity=lasagne.nonlinearities.identity,\n",
    "            num_units=1024)\n",
    "print(\"[Parameter Memory (binary)]\", \"(1024, 1024)\")\n",
    "print(\"[Data Memory (binary)]\", inject_batch_size(cnn.output_shape, batch_size))\n",
    "\n",
    "cnn = lasagne.layers.BatchNormLayer(\n",
    "        cnn,\n",
    "        epsilon=epsilon, \n",
    "        alpha=alpha)\n",
    "\n",
    "cnn = lasagne.layers.NonlinearityLayer(\n",
    "        cnn,\n",
    "        nonlinearity=activation)\n",
    "\n",
    "cnn = binary_net.DenseLayer(\n",
    "            cnn, \n",
    "            binary=binary,\n",
    "            stochastic=stochastic,\n",
    "            H=H,\n",
    "            W_LR_scale=W_LR_scale,\n",
    "            nonlinearity=lasagne.nonlinearities.identity,\n",
    "            num_units=10)\n",
    "print(\"[Parameter Memory (binary)]\", \"(1024, 10)\")\n",
    "print(\"[Data Memory (binary)]\", inject_batch_size(cnn.output_shape, batch_size))\n",
    "\n",
    "cnn = lasagne.layers.BatchNormLayer(\n",
    "        cnn,\n",
    "        epsilon=epsilon, \n",
    "        alpha=alpha)\n",
    "\n",
    "train_output = lasagne.layers.get_output(cnn, deterministic=False)\n",
    "\n",
    "# squared hinge loss\n",
    "loss = T.mean(T.sqr(T.maximum(0.,1.-target*train_output)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
